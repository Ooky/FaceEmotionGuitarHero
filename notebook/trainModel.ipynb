{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "We are going to train a convolutional neural network (cnn) to recognize facial emotions. Then we use the output of the emotions to play a game in a browser which is like guitarhero. Instead of pressing the matching button at the right time, you can use your face and make the same emotion as needed. Our program then checks wheter you did a good job (same emotion) or if you weren't that clear with your facial emotion!\n",
    "\n",
    "\n",
    "## Dataset\n",
    "\n",
    "As a dataset, we use videos from 23 different actors who sing and say a sentence in eight different emotions. \n",
    "Our old approach was the following: We will seperate the videos into each emotion and then take several screenshots from the video.\n",
    "Our new approach is to use a face landmark recognition api too feed our model with our data to train it on different emotions.\n",
    "\n",
    "\n",
    "## Credits\n",
    "\n",
    "\n",
    "Credits:\n",
    "\"[The Ryerson Audio-Visual Database of Emotional Speech and Song (RAVDESS)](https://zenodo.org/record/1188976)\" by Livingstone & Russo is licensed under [CC BY-NA-SC 4.0.](https://creativecommons.org/licenses/by-nc-sa/4.0/)\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programme\\Anaconda3\\envs\\tf\\lib\\site-packages\\h5py\\__init__.py:72: UserWarning: h5py is running against HDF5 1.10.2 when it was built against 1.10.3, this may cause problems\n",
      "  '{0}.{1}.{2}'.format(*version.hdf5_built_version_tuple)\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.2.4'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the data\n",
    "\n",
    "First of all we inport os, shutil and glob. glob is used to match path names.\n",
    "We are going to copy every video into one folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil, glob\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of instances:  35888\n"
     ]
    }
   ],
   "source": [
    "with open(\"D:/Arbeit/semester5/comppx18/Projekt/Datasets/KaggleEmotion/fer2013/fer2013.csv\") as f:\n",
    "    content = f.readlines()\n",
    "\n",
    "    lines = np.array(content)\n",
    "\n",
    "    num_of_instances = lines.size\n",
    "print(\"number of instances: \",num_of_instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = [], [], [], []\n",
    "for i in range(1,num_of_instances):\n",
    "    try:\n",
    "        emotion, img, usage = lines[i].split(\",\")\n",
    "\n",
    "        val = img.split(\" \")\n",
    "        pixels = np.array(val, 'float32')\n",
    "        emotion = keras.utils.to_categorical(emotion, 7)\n",
    "        if 'Training' in usage:\n",
    "            y_train.append(emotion)\n",
    "            x_train.append(pixels)\n",
    "        elif 'PublicTest' in usage:\n",
    "            y_test.append(emotion)\n",
    "            x_test.append(pixels)\n",
    "    except:\n",
    "        print(\"\", end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(y_train)\n",
    "x_train = np.array(x_train)\n",
    "y_test = np.array(y_test)\n",
    "x_test = np.array(x_test)\n",
    "x_train = x_train.reshape((len(x_train),48,48)+(1,))\n",
    "x_test = x_test.reshape((len(x_test),48,48)+(1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28709, 48, 48, 1)\n"
     ]
    }
   ],
   "source": [
    "#np.concatenate((np.ones((len(x_train),1), dtype=np.int), x_train.reshape(len(x_train),1)), axis=1)\n",
    "#print(x_train.shape)\n",
    "#x_train = np.insert(x_train, 0, values=30, axis=1) \n",
    "#print(x_train)\n",
    "#print(x_train.shape)\n",
    "print(x_train.shape)\n",
    "#x_train = x_train.reshape((len(x_train), len(x_train[0])))\n",
    "#x_train = x_train.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import AveragePooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    " \n",
    "#1st convolution layer\n",
    "model.add(Conv2D(64, (5, 5), activation='relu', input_shape=(48,48,1)))\n",
    "model.add(MaxPooling2D(pool_size=(5,5), strides=(2, 2)))\n",
    " \n",
    "#2nd convolution layer\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(AveragePooling2D(pool_size=(3,3), strides=(2, 2)))\n",
    " \n",
    "#3rd convolution layer\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(AveragePooling2D(pool_size=(3,3), strides=(2, 2)))\n",
    " \n",
    "model.add(layers.Flatten())\n",
    " \n",
    "#fully connected neural networks\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    " \n",
    "model.add(Dense(7, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "\n",
    "#1st convolution layer\n",
    "model.add(Conv2D(64, (5, 5), activation='relu', input_shape=(48,48,1)))\n",
    "model.add(MaxPooling2D(pool_size=(5,5), strides=(2, 2)))\n",
    "\n",
    "#2nd convolution layer\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(AveragePooling2D(pool_size=(3,3), strides=(2, 2)))\n",
    "\n",
    "#3rd convolution layer\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(AveragePooling2D(pool_size=(3,3), strides=(2, 2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "#fully connected neural networks\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "#------------------------------\n",
    "#batch process\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "gen = ImageDataGenerator()\n",
    "train_generator = gen.flow(x_train, y_train, batch_size=256)\n",
    "\n",
    "#------------------------------\n",
    "\n",
    "model.compile(loss='categorical_crossentropy'\n",
    "    , optimizer=keras.optimizers.Adam()\n",
    "    , metrics=['accuracy']\n",
    ")\n",
    "\n",
    "#------------------------------\n",
    "\n",
    "model.load_weights('facial_expression_model_weights.h5') #load weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      " 32/128 [======>.......................] - ETA: 33:40 - loss: 13.5400 - acc: 0.1343"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-259-27d9d4dd33a4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m )\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Programme\\Anaconda3\\envs\\compx\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programme\\Anaconda3\\envs\\compx\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1418\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1420\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programme\\Anaconda3\\envs\\compx\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[0;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m                                             class_weight=class_weight)\n\u001b[0m\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programme\\Anaconda3\\envs\\compx\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1217\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1218\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programme\\Anaconda3\\envs\\compx\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programme\\Anaconda3\\envs\\compx\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programme\\Anaconda3\\envs\\compx\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1449\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1450\u001b[0m           return tf_session.TF_SessionRunCallable(\n\u001b[1;32m-> 1451\u001b[1;33m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[0;32m   1452\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,)\n",
    "batch_size = 256\n",
    "gen = ImageDataGenerator()\n",
    "train_generator = gen.flow(x_train, y_train, batch_size=batch_size)\n",
    " \n",
    "model.compile(loss='categorical_crossentropy'\n",
    ", optimizer=keras.optimizers.Adam()\n",
    ", metrics=['accuracy']\n",
    ")\n",
    "model.fit_generator(train_generator, steps_per_epoch=batch_size, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"faceEmotionWithGivenWeights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"models/faceEmotionWithGivenWeights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_21 (Conv2D)           (None, 44, 44, 64)        1664      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 20, 20, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 18, 18, 64)        36928     \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "average_pooling2d_9 (Average (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 5, 5, 128)         73856     \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 3, 3, 128)         147584    \n",
      "_________________________________________________________________\n",
      "average_pooling2d_10 (Averag (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1024)              132096    \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 7)                 7175      \n",
      "=================================================================\n",
      "Total params: 1,485,831\n",
      "Trainable params: 1,485,831\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''from sklearn.metrics import classification_report, confusion_matrix\n",
    "pred_list = []; actual_list = []\n",
    "for i in predictions:\n",
    "pred_list.append(np.argmax(i))\n",
    "for i in y_test:\n",
    "actual_list.append(np.argmax(i))\n",
    "confusion_matrix(actual_list, pred_list)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def emotion_analysis(emotions):\n",
    "    objects = ('angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral')\n",
    "    y_pos = np.arange(len(objects))\n",
    "\n",
    "    plt.bar(y_pos, emotions, align='center', alpha=0.5)\n",
    "    plt.xticks(y_pos, objects)\n",
    "    plt.ylabel('percentage')\n",
    "    plt.title('emotion')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJztnWusX1WZxp+3pdBSyqW01Np7K5eiHWhygAokGvDCAAIfgAiGMAaDHwYDAUScSQiYGUVj1MSZOHKLnYQIok0gIBlJh0tAUihyGaD0hlIOPe2h0EK5CKVd8+H8a7qf9bT/xek5/3OO6/klpF2btfdea+39dp/3Oe/7rkgpwRhTF6OGegDGmM5jwzemQmz4xlSIDd+YCrHhG1MhNnxjKsSGb0yF2PCNqZC9MvyIOC0iVkbEmoi4dqAGZYwZXKK/kXsRMRrAKgBfBNAN4EkAF6SUXtzdOWPHjk3jx49vHPvwww8b7dGjR2fn7bfffo329u3bsz4fffRR2zF/8MEHjfb++++f9YmIRlutz/vvv99o77PPPlmfUaPyf1P5mJoH33/cuHFZH54HryGg15Hhue3YsaPtOUA+D7VGJe8Vz5XbJeeo8ah3gfsM5Fx5/VUfvo56Pvvuu2+jPWnSpKwPz5/vvWnTJmzdurXtQuZvbDnHA1iTUnq5NaA7AJwNYLeGP378eJxxxhmNY6+++mqjfeCBB2bnzZkzp9F+++23sz69vb2NtjLGtWvXNtoLFizI+vA/MmxkALBixYpG+5BDDsn6HHDAAW2v/e6772Z9+IX4zGc+k/V5+eWXG+3u7u6sz0EHHZQdY9hA1HiUofELum3btqwPv/zKGMeMGbPHtkL1mTBhQqO9cePGrA8/j/feey/ro/4xaPehAvJ3WF2H1+zggw/O+syePbvR/vrXv5714fmvW7eu0b7++uuzcxR786P+NAC7zri7dcwYM8zZG8NXP05kP+NExKURsTwilquvpzGm8+yN4XcDmLFLezqA9dwppXRTSqkrpdTFP+oaY4aGvfHxnwRweETMAfAagK8CuHBPJ4waNSrzc9nXUWJWT09Po638LPbZlN/J91IC3ObNm9ve69BDD220DzvssKzPO++8kx176623smPM1q1b257D41Z6BjN27NjsGGslaj3Yfwb0mjAsXCrNg1E/EfKY1MeDdSG1ZqwxlH6EWABWOgjrGUq05fdRveeMWmdex6OOOqrRVs9Z0W/DTyl9FBGXAfgfAKMB3JZSeqG/1zPGdI69+eIjpfR7AL8foLEYYzqEI/eMqZC9+uJ/XHbs2JEFv7z++uuNtgpaYD+PrwHkPpT6fS/7Ynzv0uuwT7lly5a211Go35FPm9b8jeiGDRuyPnw/5a+WBDTx75vV7/5Lfiet5sFahdIh2Bcu+T2+Gg/HcCitgp+9eofU/Xkeal15/srP7k9gmPpdP68Zx5CUBG4B/uIbUyU2fGMqxIZvTIXY8I2pkI6KeymlTPTiYBglzPA5SmDhQIs333wz6zNjxoxGuySrrUQkLEnuUCiBh+em5loiVHGghxIb+5uxxvdXwh0LhUoAZKFKrQevvwqOYbFR9WFUAI2af0mWIa+1ug6/a+q5slDHyT9A/g5v2rSp7XUV/uIbUyE2fGMqxIZvTIV01MePiCzYhAMklC/I/qnqw765CkaZMmVKo60KWLS7N5AHVqhEFhWIxCj/kbUJXh8g1w9KgmyU71cS7KEKozB//etfs2Ps0/J4gPw5qgIr/L6ouZYEAnESlwp6UtfmxCE119KgmXawVqPec54Hv3slVYwAf/GNqRIbvjEVYsM3pkJs+MZUSEfFPSAXtFgEUhlz3Icz2IA8gGfu3LlZHxaqlCjHYpoSpVg4VAE0qnQ3i06q4gyvT0mGFgdxqOsocY8FLiXkKXGTj6lsNB6jCsxiUUw9D76Oeh4suCnhjseorqOeY0lZbA5gUgFN/QkMU2PkuZVUX1L4i29MhdjwjakQG74xFTLkFXhKKs6wDzt//vysDydKlARVKN+UfSjlZ7FvrhI+lO/Ffp3azYXPU/PgNeTEDQB47bXXGm0VUDRx4sRGW1UGVgFEJbsN8VxLnofSIXg91PNglJ7AqEQeVQmY16RkjCVBNMrH5zVS1YL5nS3Z4kvhL74xFWLDN6ZCbPjGVIgN35gK6bi4x4LWzJkzG20VxMHi3jHHHJP14a2jWbgCcqGqJPNMCVcs3ijBRwllPCZ1/zfeeKPRLgl8UWISB/4oMYkDcZQAN3ny5OwYZxAqwY1FJnVtXls1j5IAFb5/yRZfKjBJCX68/qqyEr/TSjTmuZZUmpo6dWrWhwPD+N2zuGeM2S02fGMqxIZvTIV0PEmH4UqiKuFk4cKFjbYKKmFfVPmLXNFXVVxhv1sF2bAvqAJ4lN9fEmzB41ZaAQeaKK2Ar60qx5RUsFXryD61Wkf2zUv6KH++pPIvr39JRV+lOZRU91m3bl3WpyQQqqQSL/v4XHUXyPULfoauwGOM2S02fGMqxIZvTIXY8I2pkI6LeyyWcOCNCr5g4U6JYhzYoAI0WPhQAguLjeo6LAyp66gqMDz3EiGmZD92tR4sgHJgEADMmzev0VaBOKrkNVOyFVjJNltKgFQBVIx6Ru3GU3odfo4qOIeDekoCgdS6HnfccY22qkbF7x7fq2T7MMBffGOqxIZvTIW0NfyIuC0ieiPi+V2OTYyIByJidevP/BeOxphhS4mP/ysA/wHgv3c5di2ApSmlGyPi2lb7O+0upLbQ4uAT5S+zf6QSTkoCGdhfVHoC+0glgRbKfyzZylslavB5Siso2SZ748aNjfaiRYuyPj09PY22ClYqqWqrAlbYF1Y6AJ+n/Gdej5KkqZLEHrX2aq3Zp1ZJOjxGVTmH11FVTVqwYEGjrd7PdvrOgCXppJQeAcCbzZ8NYHHr74sBnFN0N2PMsKC/Pv6UlFIPALT+PGzghmSMGWwGXdyLiEsjYnlELC/JkzbGDD79NfyNETEVAFp/9u6uY0rpppRSV0qpq6RCqjFm8OlvAM89AC4GcGPrz7tLT2wnTKkgCs7YmzVrVtvrKoGHxSv1Ewhfh6vNqDGq4BhVzppLXiuhiEVKJTjxmqlMs1NPPbXR5kApAHj33XcbbRVUooJq+B9wJbaySKoEL15H9cz4OmrN+DkqYbVE9FL35/upzFC+NgcmAWXbtz388MON9oknnpj14WfN73RJoBJQ9uu8XwN4HMCREdEdEZegz+C/GBGrAXyx1TbGjBDafvFTShfs5n+dupvjxphhjiP3jKmQjibpjBo1KgtiYX9IJRmoCjcM+6LKF3vmmWcabeX3cWKEuveWLVsabaUV/PnPf86O8VxVMMonP/nJRlv574cd1vztqfLruru7216HfWylr6gAJr4W30uhgnx43VTFGX6uaozsmysdgOdRoq8AuQ+t1pHfWVWZuGSMXCGK3zMgnz/rNCUJS4C/+MZUiQ3fmAqx4RtTITZ8Yyqk4+Iei2Us3qhtg1h0KdlbXIkcJ5xwQqNdstWREgl7e5uBips3b876qOopfG0VnMOBLkcccUTWh0Ux3oYMyLfQUgE0JdVl1Dz+8pe/NNoqyIlFp5LtsTijEMjHrcRWFu6mTZuW9eGgo/nz52d9lLDMgTZKyOXS2dwG8vdTiYRdXV2N9pNPPpn14fd66dKljbYSBBX+4htTITZ8YyrEhm9MhdjwjamQjop777//Pp5//vnGMRZiWJQC8mi2kmgyJVSVRIGV7LHGmVZK8FHCXUmpaN6HjdulcAafKs9VUt67ZF9AFTnIa6TWkaPX1DryM+PoNnVtlVHIKNFSiXLqfWRKyqXxmNTaP/roo422Eo05+pTfqZK9BgF/8Y2pEhu+MRViwzemQjoewMN+HfskKmCG/SzlU7JvroJ82K9SPiWfp3QA9ntVxRVVZoznrvy8kkAkPk+Vii7RE7jijgrEKalKo+C1LSmbrrLa+Fkr7YbXWvn4vGbKD+fM0VI4yEfpGTxGNQ8OvnnhhReyPvxc2TZKSosD/uIbUyU2fGMqxIZvTIXY8I2pkI6Ke/vttx/mzp3bOMYZWf3ddKPdvuFALvAoAZADXUr2U+NgFUCLLHw/JQKpYwyXGy/JVlQCIJ+nxC0V+MNzU6WiuY96riVzZUpLSzEsrqnno0qxcVCPGrPac5Dh91GVX+dMu5K97lk0HbC984wxf3/Y8I2pEBu+MRXSUR9/3Lhx2R7gHLSg/CX2zUt8Y9WH/SFV8pmDc0q22VL+otIGSnx8HpPy39nvVIk07AsrX52r26gxq2ApHqM6j9dEBazw2qrAm5LnysdUsBCvR0mAF1AW1MNzU1uqcTLaY489lvXhAKqSdeUgrBJdAPAX35gqseEbUyE2fGMqxIZvTIV0VNxLKWVi0XHHHddov/TSS9l5HOTDe8cpVMAKCyNqr7aSABEWfEqywdT9lQjFwTBKhOKqPEpc5OotSgDk66iKLyUCkxKUSkQmnpvKaGRKsvxUJZ2SfeO5JDiQZyKqZ83inlozzjpV+w3y/NWzLw3QaYe/+MZUiA3fmAqx4RtTIR318UuYNWtWdoyrjpT4OSVJOiWJKyX3Kk3cUMksTMkY2c8tqbajxshahVozVRGJUb4oj1vNg+daUtG3RDtQ/jyPUWkFSvN55ZVXGm1V5Zfnpsa4aNGiRltpWf2BA7OcpGOM2S02fGMqxIZvTIW0NfyImBERD0bEioh4ISIubx2fGBEPRMTq1p+5g2SMGZZEOzEgIqYCmJpS+lNETADwFIBzAPwTgDdTSjdGxLUADkkpfWdP15owYUI69thjG8fOP//8RlttbcQBEqXbBDEcIKEEJ0YFbJQITCqIhOnp6cmOscClgkF4HirwhAU/JQDys1cBPJzBB+TrVlJdRwmAJVuRsVBXInaqd5rHo/qo7bJeffXVRlsFj/G11PvJQubq1auzPiwIq3ePg6e4vXLlSrz33ntt90Zr++anlHpSSn9q/X0rgBUApgE4G8DiVrfF6PvHwBgzAvhYPn5EzAawEMAyAFNSSj1A3z8OAGQcbURcGhHLI2J5f+ulGWMGlmLDj4gDAPwOwBUppbfb9d9JSummlFJXSqlL/bhnjOk8RQE8ETEGfUZ/e0ppSevwxoiYmlLqaekAve2uM2bMmKwSySOPPNJoq0CTT33qU4222sKpJAmjpA/7ZyV+Z4kfDgDLli1rtNWWURyQoX5KKtlemnUI5eNzJR11HZVsxL6nShLiykoq8IW1CeUblwTesN9fUkFXPTN1jN9X9fHi9+Fzn/tc1uf2229vtJVWwe+DCp5qFxhVWrm4RNUPALcCWJFS+sku/+seABe3/n4xgLuL7miMGXJKvvgnAbgIwP9FxDOtY/8C4EYAv4mISwCsA3De4AzRGDPQtDX8lNKjAHb364FTB3Y4xphO4Mg9Yyqk49l57faoV2WYS0S5dtctOQfIRSAV6MGCihJ8VOALl09m4QjIx61EoJJAj5IsrZJ5qBLk7a4D5CITB8IAwIwZMxrtgw46KOvDoqQS7vg5KgGQBVHVR12b30dVppyfx3333df22lOmTMn68LMvKTXfX/zFN6ZCbPjGVIgN35gK6aiPP2rUqCywhX1B5cPwlkTKF2SftsR/V31YTyjZVklpECtWrGh7bZXIw0EbJb660kVKqhaxb678+f5WACrZZoyDjFTACvdRa8bzV8+DA6GOPvrorI/y+5977rlGW22pVZI0xefx1ldAvtYqUI39fp57qQbgL74xFWLDN6ZCbPjGVIgN35gK6XgADwsYXNFk0qRJ2TksWCihisWj/ub+c4aWEnxYkOztzRMTVaDHZz/72Y99f5UxxmNSYhaLYio4h6+jhDMViFSyhRZXs1m1alXb+6vy2vzslUjIz6MkO0+JlldccUV2rN14Sq/dH/G5BF5DLuO9O/zFN6ZCbPjGVIgN35gKseEbUyEdFfdmz56NW265ZY99SiKPrr766uwYi0kl1ynZz02V0GIRRpUEnz59enaMo66UAMkRXiqajseoyi1xNJ1aD84GU+KSEvx4TKqsFs9VZZrxGJUgyvsNqudRIgDyPC677LKsj1rHEsGt5F0bqD5MSeSrwl98YyrEhm9MhdjwjamQIQ/g6U+lmO9///tZnx//+MeNdsk2Vyqohc9T/iJnX5UEbAD5FlUqi4sDMj7xiU9kfTjQpaQstvKfuY+q5KPYsGFDo622g2KNo0QHUFVpeIzqmZUEx/CalQT5/D3jL74xFWLDN6ZCbPjGVIgN35gK6bi4NxAZSEqY4TJFXK5L3VsJgCV7tZWgSitxaSkl7jEqO45LjynhjOemxsPXVuuhAohYpFRZdXxtFXhTUt6bsxNLgq7Udc4888w9ngNY3DPG/J1jwzemQmz4xlRIx338gaDEz1Mlpzkppr9+HgfDlGzxBeS+sErSYU2Bt91S91M6AI9R+eHsd5fOgxNnVAAR6zAlCTDKN2dKklDUs1+wYEHb82rCX3xjKsSGb0yF2PCNqRAbvjEVMiLFPSXwcICKEoqUKMiUZHrxtdV11b5nHHijhEQOolEBRK+99lqjrcp7c3UbJcBxaXMlwKl5cJWgElFO7YvHmYdqD74DDzyw0VbCHVdfuuqqq7I+PLeagnUU/uIbUyE2fGMqpK3hR8TYiHgiIp6NiBci4obW8TkRsSwiVkfEnRGRB2MbY4YlJT7+BwBOSSm9ExFjADwaEfcDuBLAT1NKd0TEfwG4BMAvBnGsf0P5Z+z7KZ+2BPbpVeIKH5s4cWLb8QDApk2bGu0tW7a0HY+aB/vdHFADAFOnTm20VXWdkmpDSmMo8Y/ZN2ddAgAmT57caKtEHq6Oq57HySef3GgrraJkG7aaaPvFT33sTNEa0/ovATgFwG9bxxcDOGdQRmiMGXCKfPyIGB0RzwDoBfAAgLUAtqSUdsZ4dgOYNjhDNMYMNEWGn1LanlI6FsB0AMcDmK+6qXMj4tKIWB4Ry9XGE8aYzvOxVP2U0hYADwFYBODgiNjpFE4HsH4359yUUupKKXWxT2eMGRrainsRMRnAtpTSlogYB+ALAH4I4EEA5wK4A8DFAO4ezIHuihKcWAQryQZTfRgVwMNZbEqUUnA56fXr838rDz/88Eb7yCOPzPpwIJAK4PnjH//YaHd1dWV9uAKQWldVuYfLax9yyCFZn5LS2TwPDgxSYzrqqKOyPscff3x2jKldzGNKVP2pABZHxGj0/YTwm5TSvRHxIoA7IuLfADwN4NZBHKcxZgBpa/gppecALBTHX0afv2+MGWE4cs+YChmRSTrKN2f/sCRgRfm07K+rPhxAw1Vnd3ce+8vd3d1Zn3PPPbfRLvFNVbDQWWedtcd7A7kfrpJtZs+enR3jqkBK4+BgoJKtq5WPz3M78cQTsz4lWo1p4i++MRViwzemQmz4xlSIDd+YCum4uFdSHplhgUsJZ/PmzWu0n3322bbXUajsL4bnwNs8AbrizNq1axtttT3VDTfc0GhzkAuQB8xwJh6QC2eqks6SJUsabSWucZluAJgzZ06jrbbwUmIeU5IdyCXI+d5ALu71d9uzmvAX35gKseEbUyE2fGMqZMi3yWZ/+fHHH8/O+cEPftBo33XXXVkf9p9V5Vu+t9oyio+xrwzk/rvaCktpBZMmTWq0e3p6sj4lW09xNRsVQMTVfdR6sE+vqtwqjWHGjBnZMYbnr9aR4YAidf+S52ra4y++MRViwzemQmz4xlSIDd+YCumouLdjx46s6svNN9/caD/xxBPZeVzx5Ze//GXWp2Rvd67So4KJWGBS4poS8xje1gnIx6juz0KVyqrjgCF1He6jgow4OEdl582cOTM7xhlzKmCmZIx8HZVRyWW6SyorKVxeu4m/+MZUiA3fmAqx4RtTIR318VevXo3TTz+9OQAKWFHJJBdeeGGjrfwz9uGU38l9lC7Afi5vewXkwSkqqERVxfn0pz/daKsKPCUJJzx/ldzCGoParovPU+uhKuhy4I/SPDgYSAUCscag5vGNb3wjO9YfavfpGX/xjakQG74xFWLDN6ZCbPjGVEjHA3g4SINFFyUCsXikgjg4Y071YfFKCT58HSV4sZin7qUyzfha48aNy/rwmFQFnAkTJjTaKqvurbfearRVCWwuk62y7tR+h7xGKhORn5kKzuF1VGt93XXXNdpqXfnYySefnPW58sorG2317GvK/PMX35gKseEbUyE2fGMqxIZvTIV0VNzbtm1bVm6KBS4lAk2fPr3RViIUX0dFk7FQo4Qbvo4SnLgsthozC3BAXnpLRcW9/vrrbcfIohxnHQK5mKdKefMaqT3sOZsSyKMJ1f1LoiR5jCpyj7P8TjrppLb3uvXWfMf2hx56qNFWwqqKbrz//vsb7f5mBw43/MU3pkJs+MZUiA3fmArpqI+///77Y+HChY1ja9asabRVxZnHHnus0b7ggguyPiUZc+zXKZ+OS1eryjGc+aYq1yhYC1DBSr29vY22yvLjuam58tyUH87+6vz587M+KjuRg4pKKgmpLcU4E7PEV3744YezY1/+8pcbbaUDcGWnEl0CAM4///xGW+kH/D6MBJ/fX3xjKsSGb0yFFBt+RIyOiKcj4t5We05ELIuI1RFxZ0TkweDGmGHJx/niXw5gxS7tHwL4aUrpcACbAVwykAMzxgweReJeREwHcAaAfwdwZfSpIKcA2FkTazGA6wH8Yk/XGT9+PE444YTGMd4rr2SvOiXCsFBVkjGmgmw400sJZxx4o4JjVMksDmJRATxcTloFtbAAqIJjeB1nz56d9Zk3b16jvX79+qyPyurjNVLiJgfeqMAXFjtV2TUOIFJi54MPPthoq2fGQV9KbFR7GfL9L7rooqzPkiVLGm01Vx7TUAuApV/8nwG4BsDOt/lQAFtSSjvfuG4A0wZ4bMaYQaKt4UfEmQB6U0pP7XpYdJX/hEXEpRGxPCKWq/BPY0znKflR/yQAZ0XE6QDGAjgQfT8BHBwR+7S++tMB5D8nAkgp3QTgJgCYNm3a8P8FpzEV0NbwU0rfBfBdAIiIzwO4OqX0tYi4C8C5AO4AcDGAu9tda/To0ZkPe8455zTaS5cuzc5jH/buu/NbnXbaaY228vPYF1X7yrM2oLQC9nGV5qD8bg70UNoAB/VwJR0gr4qjKvC0OwfI10MlGymNgY+phKiSMuH8jFTwFmsMKvCmZEsvvpfSd9Qz46SpN954I+vzzW9+s9E+4ogjsj7f/va3G23l4yttYLDYm9/jfwd9Qt8a9Pn8eUiTMWZY8rFCdlNKDwF4qPX3lwEcP/BDMsYMNo7cM6ZCbPjGVEhHs/OAXGTh/eTuu+++7BwWPV588cWsz1e+8pVGWwlOLMJNnDgx68OiixJcWOBRASxK8OMgEiWm8b50KoCGx6jELBYJOaAGyAOBWHgFdAUenpu6NqNE0pL9DjkTUAXw8LVL9lZUATyqKg8LfmqML730UqPNIi4AXHPNNY22ej9/9KMfNdpqXXke/Q0E8hffmAqx4RtTITZ8Yyqkoz5+SikLNmGf5Utf+lJ2Hgf1qGSOn//85402B1UAefCH8js5cUZV6eHrKD9caQOrV69utFXizKpVqxrtEq1CaQwqOInh85S/qLas4vkrv5uvXVKlSM2VNSHlY/N5KniLUc9H3b8EXiM1Rn7X1P2vuuqqRlut64IFCxptThoq9fn9xTemQmz4xlSIDd+YCrHhG1MhHRf32gkoHMAC5Nlgas94FthKSj4rcW/u3LmN9lNPPZX14Xup8ahgEO6nBDi+dkklITVXRok+fEyNR53HY1JZhiySlgh36l4sJKo+SkxjSoJ8VHYgZ+epteYxsogLANOmNevUqPvzeihhmd9HrmC1bt267ByFv/jGVIgN35gKseEbUyEd9fG3b9+e+VGc8KJ8Wq4ew0EuQJ7wcvPNN2d9Lr/88ka7u7s768O+6KxZs7I+K1eubLRVZWClVbAvrO7PKJ+yJBiEA2ZU5RpeM1VtR8HJPKpKUIkOwcFcKhCKg1jU+8HXUT4/r4dKPlLbhXGlng0bNmR9eP3VNu48JjUP7qOeKwcL8fqU6D2Av/jGVIkN35gKseEbUyE2fGMqpKPi3qhRozIxgoUQ3p8eyPdtV1ltf/jDHxptVWHle9/7XqOtyil/61vfyo4x/dkeCshFqJKy3CVilhKqOINRiY0srCpxTQllvLYqWImrG6mAFRbcVJAP31+VxebAKFVunPuo8ZQEVKmqOCxYq3nw+6AyCHmuJZWd+NmXBDMB/uIbUyU2fGMqxIZvTIV01MffsWOH9H13RQU/rFmzptFWPu15553XaN95551ZH/arlE972223NdpqO6Surq5Ge8WKFVkf5Zuz362q2zDKp+T5K/+dfViVgFISMKJgP1tt983XVs+sRCvh66hgoZKqM6ydqOuoACYet0rImjlz5h7vBeRzUwFV/M6oPjzGkgrHCn/xjakQG74xFWLDN6ZCbPjGVEj0dwueft0s4nUArwCYBCBPhRrejMQxAyNz3B5z/5mVUprcrlNHDf9vN41YnlLqat9z+DASxwyMzHF7zIOPf9Q3pkJs+MZUyFAZ/k1DdN+9YSSOGRiZ4/aYB5kh8fGNMUOLf9Q3pkI6bvgRcVpErIyINRFxbafvX0JE3BYRvRHx/C7HJkbEAxGxuvVnHqA+hETEjIh4MCJWRMQLEXF56/iwHXdEjI2IJyLi2daYb2gdnxMRy1pjvjMi8qSKISYiRkfE0xFxb6s97Me8Kx01/IgYDeA/AfwjgKMBXBARR3dyDIX8CsBpdOxaAEtTSocDWNpqDyc+AnBVSmk+gEUA/rm1tsN53B8AOCWldAyAYwGcFhGLAPwQwE9bY94M4JIhHOPuuBzArtlZI2HMf6PTX/zjAaxJKb2cUvoQwB0Azu7wGNqSUnoEwJt0+GwAi1t/XwzgnI4Oqg0ppZ6U0p9af9+KvpdyGobxuFMfO2uOj2n9lwCcAuC3rePDaswAEBHTAZwB4JZWOzDMx8x02vCnAXh1l3Z369hIYEpKqQfoMzIAhw3xeHZLRMwGsBDAMgzzcbd+ZH4GQC+ABwCsBbAlpbQzt3U4viM/A3ANgJ05w4di+I//3UuyAAABgElEQVS5QacNX1X7968VBpCIOADA7wBckVLKk/CHGSml7SmlYwFMR99PhPNVt86OavdExJkAelNKu+5eOeLe644W4kDfv4S7VtqYDmB9h8fQXzZGxNSUUk9ETEXfF2pYERFj0Gf0t6eUlrQOD/txA0BKaUtEPIQ+feLgiNin9QUdbu/ISQDOiojTAYwFcCD6fgIYzmPO6PQX/0kAh7cU0H0BfBXAPR0eQ3+5B8DFrb9fDODuIRxLRsvPvBXAipTST3b5X8N23BExOSIObv19HIAvoE+beBDAua1uw2rMKaXvppSmp5Rmo+/9/d+U0tcwjMcsSSl19D8ApwNYhT5f7l87ff/CMf4aQA+Abej7KeUS9PlxSwGsbv05cajHSWM+GX0/Xj4H4JnWf6cP53ED+AcAT7fG/DyA61rH5wJ4AsAaAHcB2G+ox7qb8X8ewL0jacw7/3PknjEV4sg9YyrEhm9MhdjwjakQG74xFWLDN6ZCbPjGVIgN35gKseEbUyH/D2n9KiivfqE4AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "img = image.load_img(\"C:/Users/mike/Pictures/Camera Roll/old/a2.jpg\", grayscale=True, target_size=(48, 48))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis = 0)\n",
    "x /= 255\n",
    "custom = model.predict(x)\n",
    "emotion_analysis(custom[0])\n",
    "x = np.array(x, 'float32')\n",
    "x = x.reshape([48, 48]);\n",
    "plt.gray()\n",
    "plt.imshow(x)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "face_cascade = cv2.CascadeClassifier('D:/Programme/Anaconda3/envs/compx/Library/etc/haarcascades/haarcascade_frontalface_default.xml')\n",
    "img = cv2.imread('C:/Users/mike/Pictures/Camera Roll/sad4.jpg')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "for (x,y,w,h) in faces:\n",
    "    cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "    cv2.imshow('img',img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
