{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "We are going to train a convolutional neural network (cnn) to recognize facial emotions. Then we use the output of the emotions to play a game in a browser which is like guitarhero. Instead of pressing the matching button at the right time, you can use your face and make the same emotion as needed. Our program then checks wheter you did a good job (same emotion) or if you weren't that clear with your facial emotion!\n",
    "\n",
    "\n",
    "## Dataset\n",
    "\n",
    "As a dataset, we use videos from 23 different actors who sing and say a sentence in eight different emotions. \n",
    "Our old approach was the following: We will seperate the videos into each emotion and then take several screenshots from the video.\n",
    "Our new approach is to use a face landmark recognition api too feed our model with our data to train it on different emotions.\n",
    "\n",
    "\n",
    "## Credits\n",
    "\n",
    "\n",
    "Credits:\n",
    "\"[The Ryerson Audio-Visual Database of Emotional Speech and Song (RAVDESS)](https://zenodo.org/record/1188976)\" by Livingstone & Russo is licensed under [CC BY-NA-SC 4.0.](https://creativecommons.org/licenses/by-nc-sa/4.0/)\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programme\\Anaconda3\\envs\\compx\\lib\\site-packages\\h5py\\__init__.py:72: UserWarning: h5py is running against HDF5 1.10.2 when it was built against 1.10.3, this may cause problems\n",
      "  '{0}.{1}.{2}'.format(*version.hdf5_built_version_tuple)\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.2.4'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the data\n",
    "\n",
    "First of all we inport os, shutil and glob. glob is used to match path names.\n",
    "We are going to copy every video into one folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil, glob\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of instances:  35888\n"
     ]
    }
   ],
   "source": [
    "with open(\"D:/Arbeit/semester5/comppx18/Projekt/Datasets/KaggleEmotion/fer2013/fer2013.csv\") as f:\n",
    "    content = f.readlines()\n",
    "\n",
    "    lines = np.array(content)\n",
    "\n",
    "    num_of_instances = lines.size\n",
    "print(\"number of instances: \",num_of_instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = [], [], [], []\n",
    "for i in range(1,num_of_instances):\n",
    "    try:\n",
    "        emotion, img, usage = lines[i].split(\",\")\n",
    "\n",
    "        val = img.split(\" \")\n",
    "        pixels = np.array(val, 'float32')\n",
    "        emotion = keras.utils.to_categorical(emotion, 7)\n",
    "        if 'Training' in usage:\n",
    "            y_train.append(emotion)\n",
    "            x_train.append(pixels)\n",
    "        elif 'PublicTest' in usage:\n",
    "            y_test.append(emotion)\n",
    "            x_test.append(pixels)\n",
    "    except:\n",
    "        print(\"\", end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(y_train)\n",
    "x_train = np.array(x_train)\n",
    "y_test = np.array(y_test)\n",
    "x_test = np.array(x_test)\n",
    "x_train = x_train.reshape((len(x_train),48,48)+(1,))\n",
    "x_test = x_test.reshape((len(x_test),48,48)+(1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28709, 48, 48, 1)\n"
     ]
    }
   ],
   "source": [
    "#np.concatenate((np.ones((len(x_train),1), dtype=np.int), x_train.reshape(len(x_train),1)), axis=1)\n",
    "#print(x_train.shape)\n",
    "#x_train = np.insert(x_train, 0, values=30, axis=1) \n",
    "#print(x_train)\n",
    "#print(x_train.shape)\n",
    "print(x_train.shape)\n",
    "#x_train = x_train.reshape((len(x_train), len(x_train[0])))\n",
    "#x_train = x_train.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import AveragePooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    " \n",
    "#1st convolution layer\n",
    "model.add(Conv2D(64, (5, 5), activation='relu', input_shape=(48,48,1)))\n",
    "model.add(MaxPooling2D(pool_size=(5,5), strides=(2, 2)))\n",
    " \n",
    "#2nd convolution layer\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(AveragePooling2D(pool_size=(3,3), strides=(2, 2)))\n",
    " \n",
    "#3rd convolution layer\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(AveragePooling2D(pool_size=(3,3), strides=(2, 2)))\n",
    " \n",
    "model.add(layers.Flatten())\n",
    " \n",
    "#fully connected neural networks\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    " \n",
    "model.add(Dense(7, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      " 32/128 [======>.......................] - ETA: 33:40 - loss: 13.5400 - acc: 0.1343"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-259-27d9d4dd33a4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m )\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Programme\\Anaconda3\\envs\\compx\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programme\\Anaconda3\\envs\\compx\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1418\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1420\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programme\\Anaconda3\\envs\\compx\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[0;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m                                             class_weight=class_weight)\n\u001b[0m\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programme\\Anaconda3\\envs\\compx\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1217\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1218\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programme\\Anaconda3\\envs\\compx\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programme\\Anaconda3\\envs\\compx\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programme\\Anaconda3\\envs\\compx\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1449\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1450\u001b[0m           return tf_session.TF_SessionRunCallable(\n\u001b[1;32m-> 1451\u001b[1;33m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[0;32m   1452\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,)\n",
    "batch_size = 128\n",
    "gen = ImageDataGenerator()\n",
    "train_generator = gen.flow(x_train, y_train, batch_size=batch_size)\n",
    " \n",
    "model.compile(loss='categorical_crossentropy'\n",
    ", optimizer=keras.optimizers.Adam()\n",
    ", metrics=['accuracy']\n",
    ")\n",
    "model.fit_generator(train_generator, steps_per_epoch=batch_size, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"faceEmotion1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"models/faceEmotion1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.5764017234759095\n",
      "Train accuracy: 78.45275000891569\n",
      "Test loss: 1.4702551507723967\n",
      "Test accuracy: 55.16857063331854\n"
     ]
    }
   ],
   "source": [
    "train_score = model.evaluate(x_train, y_train, verbose=0)\n",
    "print('Train loss:', train_score[0])\n",
    "print('Train accuracy:', 100*train_score[1])\n",
    " \n",
    "test_score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', test_score[0])\n",
    "print('Test accuracy:', 100*test_score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''from sklearn.metrics import classification_report, confusion_matrix\n",
    "pred_list = []; actual_list = []\n",
    "for i in predictions:\n",
    "pred_list.append(np.argmax(i))\n",
    "for i in y_test:\n",
    "actual_list.append(np.argmax(i))\n",
    "confusion_matrix(actual_list, pred_list)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def emotion_analysis(emotions):\n",
    "    objects = ('angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral')\n",
    "    y_pos = np.arange(len(objects))\n",
    "\n",
    "    plt.bar(y_pos, emotions, align='center', alpha=0.5)\n",
    "    plt.xticks(y_pos, objects)\n",
    "    plt.ylabel('percentage')\n",
    "    plt.title('emotion')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "img = image.load_img(\"C:/Users/mike/Pictures/Camera Roll/sad4.jpg\", grayscale=True, target_size=(48, 48))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis = 0)\n",
    "x /= 255\n",
    "custom = model.predict(x)\n",
    "emotion_analysis(custom[0])\n",
    "x = np.array(x, 'float32')\n",
    "x = x.reshape([48, 48]);\n",
    "plt.gray()\n",
    "plt.imshow(x)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(3.4.4) C:\\projects\\opencv-python\\opencv\\modules\\core\\src\\ocl.cpp:5410: error: (-220:Unknown error code -220) OpenCL error CL_OUT_OF_RESOURCES (-5) during call: clEnqueueWriteBuffer(q, handle=00000200AFFC9690, CL_TRUE, offset=0, sz=186432, data=00000200AF871020, 0, 0, 0) in function 'cv::ocl::OpenCLAllocator::upload'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-20740b19f9da>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'C:/Users/mike/Pictures/Camera Roll/sad4.jpg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mgray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mfaces\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mface_cascade\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetectMultiScale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfaces\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrectangle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(3.4.4) C:\\projects\\opencv-python\\opencv\\modules\\core\\src\\ocl.cpp:5410: error: (-220:Unknown error code -220) OpenCL error CL_OUT_OF_RESOURCES (-5) during call: clEnqueueWriteBuffer(q, handle=00000200AFFC9690, CL_TRUE, offset=0, sz=186432, data=00000200AF871020, 0, 0, 0) in function 'cv::ocl::OpenCLAllocator::upload'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "face_cascade = cv2.CascadeClassifier('D:/Programme/Anaconda3/envs/compx/Library/etc/haarcascades/haarcascade_frontalface_default.xml')\n",
    "img = cv2.imread('C:/Users/mike/Pictures/Camera Roll/sad4.jpg')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "for (x,y,w,h) in faces:\n",
    "    cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "    cv2.imshow('img',img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
