{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "We are going to train a convolutional neural network (cnn) to recognize facial emotions. Then we use the output of the emotions to play a game in a browser which is like guitarhero. Instead of pressing the matching button at the right time, you can use your face and make the same emotion as needed. Our program then checks wheter you did a good job (same emotion) or if you weren't that clear with your facial emotion!\n",
    "\n",
    "\n",
    "## Dataset\n",
    "\n",
    "As a dataset, we use videos from 23 different actors who sing and say a sentence in eight different emotions. \n",
    "Our old approach was the following: We will seperate the videos into each emotion and then take several screenshots from the video.\n",
    "Our new approach is to use a face landmark recognition api too feed our model with our data to train it on different emotions.\n",
    "\n",
    "\n",
    "## Credits\n",
    "\n",
    "\n",
    "Credits:\n",
    "\"[The Ryerson Audio-Visual Database of Emotional Speech and Song (RAVDESS)](https://zenodo.org/record/1188976)\" by Livingstone & Russo is licensed under [CC BY-NA-SC 4.0.](https://creativecommons.org/licenses/by-nc-sa/4.0/)\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programme\\Anaconda3\\envs\\tf\\lib\\site-packages\\h5py\\__init__.py:72: UserWarning: h5py is running against HDF5 1.10.2 when it was built against 1.10.3, this may cause problems\n",
      "  '{0}.{1}.{2}'.format(*version.hdf5_built_version_tuple)\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.2.4'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the data\n",
    "\n",
    "First of all we inport os, shutil and glob. glob is used to match path names.\n",
    "We are going to copy every video into one folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil, glob\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of instances:  35888\n"
     ]
    }
   ],
   "source": [
    "with open(\"D:/Arbeit/semester5/comppx18/Projekt/Datasets/KaggleEmotion/fer2013/fer2013.csv\") as f:\n",
    "    content = f.readlines()\n",
    "\n",
    "    lines = np.array(content)\n",
    "\n",
    "    num_of_instances = lines.size\n",
    "print(\"number of instances: \",num_of_instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = [], [], [], []\n",
    "for i in range(1,num_of_instances):\n",
    "    try:\n",
    "        emotion, img, usage = lines[i].split(\",\")\n",
    "\n",
    "        val = img.split(\" \")\n",
    "        pixels = np.array(val, 'float32')\n",
    "        emotion = keras.utils.to_categorical(emotion, 7)\n",
    "        if 'Training' in usage:\n",
    "            y_train.append(emotion)\n",
    "            x_train.append(pixels)\n",
    "        elif 'PublicTest' in usage:\n",
    "            y_test.append(emotion)\n",
    "            x_test.append(pixels)\n",
    "    except:\n",
    "        print(\"\", end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(y_train)\n",
    "x_train = np.array(x_train)\n",
    "y_test = np.array(y_test)\n",
    "x_test = np.array(x_test)\n",
    "x_train = x_train.reshape((len(x_train),48,48)+(1,))\n",
    "x_test = x_test.reshape((len(x_test),48,48)+(1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28709, 48, 48, 1)\n"
     ]
    }
   ],
   "source": [
    "#np.concatenate((np.ones((len(x_train),1), dtype=np.int), x_train.reshape(len(x_train),1)), axis=1)\n",
    "#print(x_train.shape)\n",
    "#x_train = np.insert(x_train, 0, values=30, axis=1) \n",
    "#print(x_train)\n",
    "#print(x_train.shape)\n",
    "print(x_train.shape)\n",
    "#x_train = x_train.reshape((len(x_train), len(x_train[0])))\n",
    "#x_train = x_train.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import AveragePooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    " \n",
    "#1st convolution layer\n",
    "model.add(Conv2D(64, (5, 5), activation='relu', input_shape=(48,48,1)))\n",
    "model.add(MaxPooling2D(pool_size=(5,5), strides=(2, 2)))\n",
    " \n",
    "#2nd convolution layer\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(AveragePooling2D(pool_size=(3,3), strides=(2, 2)))\n",
    " \n",
    "#3rd convolution layer\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(AveragePooling2D(pool_size=(3,3), strides=(2, 2)))\n",
    " \n",
    "model.add(layers.Flatten())\n",
    " \n",
    "#fully connected neural networks\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    " \n",
    "model.add(Dense(7, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "\n",
    "#1st convolution layer\n",
    "model.add(Conv2D(64, (5, 5), activation='relu', input_shape=(48,48,1)))\n",
    "model.add(MaxPooling2D(pool_size=(5,5), strides=(2, 2)))\n",
    "\n",
    "#2nd convolution layer\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(AveragePooling2D(pool_size=(3,3), strides=(2, 2)))\n",
    "\n",
    "#3rd convolution layer\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(AveragePooling2D(pool_size=(3,3), strides=(2, 2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "#fully connected neural networks\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "#------------------------------\n",
    "#batch process\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "gen = ImageDataGenerator()\n",
    "train_generator = gen.flow(x_train, y_train, batch_size=256)\n",
    "\n",
    "#------------------------------\n",
    "\n",
    "model.compile(loss='categorical_crossentropy'\n",
    "    , optimizer=keras.optimizers.Adam()\n",
    "    , metrics=['accuracy']\n",
    ")\n",
    "\n",
    "#------------------------------\n",
    "\n",
    "model.load_weights('facial_expression_model_weights.h5') #load weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      " 32/128 [======>.......................] - ETA: 33:40 - loss: 13.5400 - acc: 0.1343"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-259-27d9d4dd33a4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m )\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Programme\\Anaconda3\\envs\\compx\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programme\\Anaconda3\\envs\\compx\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1418\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1420\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programme\\Anaconda3\\envs\\compx\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[0;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m                                             class_weight=class_weight)\n\u001b[0m\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programme\\Anaconda3\\envs\\compx\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1217\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1218\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programme\\Anaconda3\\envs\\compx\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programme\\Anaconda3\\envs\\compx\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programme\\Anaconda3\\envs\\compx\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1449\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1450\u001b[0m           return tf_session.TF_SessionRunCallable(\n\u001b[1;32m-> 1451\u001b[1;33m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[0;32m   1452\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,)\n",
    "batch_size = 256\n",
    "gen = ImageDataGenerator()\n",
    "train_generator = gen.flow(x_train, y_train, batch_size=batch_size)\n",
    " \n",
    "model.compile(loss='categorical_crossentropy'\n",
    ", optimizer=keras.optimizers.Adam()\n",
    ", metrics=['accuracy']\n",
    ")\n",
    "model.fit_generator(train_generator, steps_per_epoch=batch_size, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"faceEmotionWithGivenWeights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"models/faceEmotionWithGivenWeights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score = model.evaluate(x_train, y_train, verbose=0)\n",
    "print('Train loss:', train_score[0])\n",
    "print('Train accuracy:', 100*train_score[1])\n",
    " \n",
    "test_score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', test_score[0])\n",
    "print('Test accuracy:', 100*test_score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''from sklearn.metrics import classification_report, confusion_matrix\n",
    "pred_list = []; actual_list = []\n",
    "for i in predictions:\n",
    "pred_list.append(np.argmax(i))\n",
    "for i in y_test:\n",
    "actual_list.append(np.argmax(i))\n",
    "confusion_matrix(actual_list, pred_list)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def emotion_analysis(emotions):\n",
    "    objects = ('angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral')\n",
    "    y_pos = np.arange(len(objects))\n",
    "\n",
    "    plt.bar(y_pos, emotions, align='center', alpha=0.5)\n",
    "    plt.xticks(y_pos, objects)\n",
    "    plt.ylabel('percentage')\n",
    "    plt.title('emotion')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "img = image.load_img(\"C:/Users/mike/Pictures/Camera Roll/old/sad.png\", grayscale=True, target_size=(48, 48))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis = 0)\n",
    "x /= 255\n",
    "custom = model.predict(x)\n",
    "emotion_analysis(custom[0])\n",
    "x = np.array(x, 'float32')\n",
    "x = x.reshape([48, 48]);\n",
    "plt.gray()\n",
    "plt.imshow(x)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "face_cascade = cv2.CascadeClassifier('D:/Programme/Anaconda3/envs/compx/Library/etc/haarcascades/haarcascade_frontalface_default.xml')\n",
    "img = cv2.imread('C:/Users/mike/Pictures/Camera Roll/sad4.jpg')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "for (x,y,w,h) in faces:\n",
    "    cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "    cv2.imshow('img',img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
